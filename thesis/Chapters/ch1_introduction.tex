
\chapter{Chapter 1. Introduction}%Be sure to include Chapter 1. before you write the name of your chapter. Name all remaining chapters in the same manner.

Accurate characterization of the distribution of water content within the soil column by land surface models is critical for governing land-atmosphere interaction in numerical weather prediction (NWP) \citep{brocca_spatial-temporal_2010} \citep{koster_contribution_2010}, operational decision making preceding and during drought and flood events \citep{otkin_assessing_2016}, and for downstream datasets aiding assessment of vegetation health, crop yield prediction, and fire risk characterization \citep{case_role_2023}. In order to address these needs, the Noah-LSM was developed to serve as the land surface component coupled to NWP models including the Weather Research and Forecasting Model (WRF), the Global Forecast System (GFS) \citep{jin_sensitivity_2010} \citep{mitchell_ncep_2005}, and climate models including the NCEP Climate Forecast System (CFSv2) \citep{saha_ncep_2014}. Noah-LSM also aids National Weather Service forecasts and US Drought Monitor designations within decision support frameworks like the Short-Term Research, Prediction, and Transition high-resolution implementation of the Land Information System (SPoRT-LIS) \citep{case_nasa_2022} \citep{case_assessment_2014}, and facilitates research and derived product development by providing soil states for NASA Land Data Assimilation System (LDAS) datasets \citep{ek_implementation_2003}.

By applying observational and reanalysis data to Noah and other land surface models, NLDAS has provided the community with consistent and quality-controlled multi-model land surface states and associated forcings in a near real-time capacity since 1999 \citep{cosgrove_real-time_2003}, with phase 2 of the project also contributing a retrospective climatology extending back to 1979. The first and second generation data products are calculated on a 1/8 degree geodetic grid spanning land-dominated points in the conterminous United States (CONUS) from 25$^\circ$ to 53$^\circ$ North latitude and 125$^\circ$-67$^\circ$ West longitude, and are released at an hourly frequency  \citep{mitchell_multi-institution_2004} \citep{xia_continental-scale_2012}. The third phase of the data assimilation system is currently under development, and aims to implement a wealth of upgrades including new data assimilation techniques and physical parameterizations, an increase in the spatial resolution to 1km$^2$, and the expansion of the domain to the full North American continent. As a consequence, the total number of valid land grid cells will increase dramatically from 76,088 in the first two phases to 27,245,580 with NLDAS-3 data products. In addition to the larger domain and updated physical processes used to develop the forcings and land surface states, the NLDAS-3 data suite will feature a variety of derived products. These products are anticipated include gridded climatological anomaly and segmented percentile data, stream routing and discharge estimates, and ensemble mean and spread information using forecast forcings \citep{kumar_north_2024}.

As the domain size and sophistication of data assimilation systems and land surface models like NLDAS and Noah-LSM continues to grow, a niche develops for methods that can generate reasonable estimates of the dynamics of numerical models which require less compute time, simplify the runtime environment of the program, and which can be fitted to observational data and then generalized to broader domains without accruing significant additional complexity to the parameterization scheme.  Data-driven modeling techniques like deep learning with artificial neural networks (ANNs) are addressing this need by introducing the ability to approximate the highly nonlinear and conditional relationships between arbitrary predictor and target datasets. This flexibility is accomplished by learning a sequence of transformations which are encoded as a composition of alternating high-dimensional matrix operations and element-wise nonlinear functions, and which serve as a mapping from the vector of predictors to a corresponding target vector \citep{hornik_multilayer_1989}.

In the context of time series physical modeling, ANNs enable the development of a statistically optimal approximation of the relationship between past states, simultaneous covariate data variables, and unknown current or future states. This general principle has a wealth of use cases. Previous literature shows that ANNs are computationally efficient and reasonably accurate for modeling dynamical systems like Lorenz'95 by formulating the problem as a discrete-time estimator of an ordinary differential equation which isn't explicitly known by the model \citep{fablet_bilinear_2018}. ANNs can also be structured to have useful properties like the ability to estimate the jacobian of the transfer mapping between inputs and future states, even if the system being emulated isn't differentiable \citep{nonnenmacher_deep_2021}. The same strategy may be applied to forecasting the evolution of datasets like ECMWF Reanalysis v5 (ERA5) in a local or global domain, however significant challenges emerge as \citep{dueben_challenges_2018} identify. As they describe, ANNs cannot be constrained by default to conserve quantities like energy and water, and unlike numerical models, their handling of the underlying physical processes as a ``black-box'' mean that identifying sources of error within the model is difficult and often speculative. Furthermore, Earth system data tend to be highly regionally variable (ex. vegetation types), exhibit nonlinear autocorrelation between multiple variables (ex. temperature, dewpoint, and cloud cover), and are subject to rare but influential outliers (ex. snow and extreme precipitation). As such, although ANNs are adept at handling very nonlinear and conditional problem types, achieving the best performance and interpretability requires the utilization of application-specific knowledge when constructing and evaluating deep learning models.

Within the field of hydrologic modeling, most of the recent literature applying deep learning methods has focused on rainfall-runoff problems, where models forecast the hydrograph of a stream given time-varying atmospheric and land surface states as well as static properties. Inputs are typically considered within a spatial boundary drawn from a watershed outlet where a streamflow station provides the prediction target by directly observing the discharge. To that end, \citep{kratzert_rainfallrunoff_2018} applies a particular ANN architecture called Long Short-Term Memory (LSTM) networks to modeling discharge from the CAMELS dataset \citep{addor_camels_2017}, which contains daily-resolution streamflow and meteorological forcings alongside parameters describing the topographic, land use, soil, and geologic properties of 671 catchments. They show that models trained on single basins often outperform models trained using data from multiple basins within a region, and that subsequent ``fine-tuning'' of a generalized regional model on individual basins slightly improves model efficiency in many cases. Later, \citep{kratzert_towards_2019} improves on LSTM model performance by modifying the training strategy to optimize an objective function similar to Nash-Sutcliffe Efficiency \citep{nash_river_1970}, and by introducing a modification to the architecture that allows for static catchment parameters to be separately provided -- and their influence separately investigated -- from time-varying inputs. These experiments even out-performed several process-based models that were tuned specifically to the individual test basins. In spite of their black-box nature, \citep{lees_hydrological_2022} demonstrates that LSTMs used for daily-scale rainfall-runoff prediction maintain information correlated with physical properties of the catchment's hydrologic state including soil moisture and snow cover, which indicates that they preserve meaningfully interpretable data about their inputs. The general approach of employing LSTMs for discharge forecasting is already being utilized by stakeholders like the United States National Weather Service and River Forecast Center offices in an operational setting with the NASA SPoRT Streamflow-AI product, which uses near real-time Noah-LSM soil moisture estimates and outlooks as an input via the SPoRT-LIS data product \citep{white_nasa_2025}, \citep{case_nasa_2022}.

Relatively few publications have applied deep learning techniques to estimate soil dynamics over a consistently spatially gridded domain, akin to the outputs of process-based models like Noah-LSM.  In one instance, \citep{filipovic_regional_2022} applied LSTMs to global daily-scale ERA5 data in order to predict the 3-day evolution of moisture content in an intermediate-depth soil layer. This is conceptually similar to emulating Noah-LSM using NLDAS forcings because ERA5 determines its soil moisture states using the ECMWF Scheme for Surface Exchanges over Land \citep{balsamo_revised_2009}. Additionally, \citep{o_global_2021} used an LSTM to assist in generalizing in-situ observations at 3 soil depth levels to a regional grid, also using daily ERA5 forcings data as an input, and adjusting predictions to match the pixel-wise gaussian parameters of the ERA5 soil moisture analysis. Both of these approaches use long lead times of 60 days or 1 year, respectively, and make predictions at only a few forecast horizons per execution of the model (3 days and 1 day, respectively).

This work seeks to apply a similar strategy of data-driven modeling for hourly-scale emulation of Noah-LSM over the full NLDAS-2 grid domain, with the goal of generating accurate and computationally reasonable forecasts out to a two-week horizon at three depth levels simultaneously. We will construct a few distinct neural network types suited to this problem structure, compare their results through a variety of bulk statistics and case studies using physical reasoning, discuss lessons learned regarding training methodology, and present a general free and open-source framework for developing time series dynamical estimators using deep learning for gridded physical datasets.
