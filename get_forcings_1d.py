"""
This script implements the procedure for selecting and extracting a series of
single-pixel datasets from NLDAS2 and Noah-LSM files from GES DISC, both of
which are on a ~14km grid.

After the user chooses a set of pixels to extract from the files in the
specified directories, the time series associated with each pixel is saved
as a GeoTimeGrid style .npy fie in gts_dir. This enables them to be recovered
"""
from datetime import datetime
from pathlib import Path
import numpy as np
import pickle as pkl

from aes670hw2 import guitools as gt
from aes670hw2 import enhance as enh

import gesdisc
import grib_tools
from GeoTimeSeries import GeoTimeSeries as GTS

def pick_pixels(X:np.ndarray, replace_val:list=None):
    """
    Choose a subset of pixels from a 2d array or 3d RGB, return their indeces.

    :@param X: (M,N) or (M,N,3) array or masked array to select pixels from.
        If X is 2D, the greyscale array will be rendered as an RGB using a
        default hue range of (0,.66) in HSV space.
    :@param replace_val: if X is a masked array and replace_val is a valid
        scalar value of the same type as X, replaces any masked values with
        the number prior to converting to RGB color space.
    """
    Y = enh.linear_gamma_stretch(X)
    if type(X)==np.ma.core.MaskedArray and not replace_val is None:
        Y = Y.data
        Y[np.where(X.mask)] = replace_val
    if len(Y.shape)==2:
        Y = gt.scal_to_rgb(Y, hue_range=(0,.66))
    return gt.get_category(Y, fill_color=(0,0,0), show_pool=False)

if __name__=="__main__":
    debug = True
    data_dir = Path("data/")

    # pkl generated by nldas_static_netcdf.py
    static_pkl = data_dir.joinpath("static/nldas2_static_all.pkl")

    # Directories containing raw hourly nldas2 and noahlsm grib1 files
    nldas_dir = data_dir.joinpath("nldas2_20180401-20180931")
    noahlsm_dir = data_dir.joinpath("noahlsm_20180401-20180931")
    # Directory where GeoTimeSeries serial arrays are deposited
    gts_dir = data_dir.joinpath("GTS")

    '''
    """ Download all of the files within the provided time range """
    init_time = datetime(year=2021, month=6, day=1)
    final_time = datetime(year=2021, month=8, day=1)
    nldas_dir = data_dir.joinpath("nldas2_20180401-20180931")
    noahlsm_dir = data_dir.joinpath("noahlsm_20180401-20180931")
    # Generate strings for each hourly nldas2 file in the time range
    nldas_urls = gesdisc.hourly_nldas2_urls(t0=init_time, tf=final_time)
    gesdisc.gesdisc_curl(nldas_urls, nldas_dir, debug=debug)
    # Generate strings for each hourly Noah-LSM file in the time range.
    lsm_urls = gesdisc.hourly_noahlsm_urls(t0=init_time, tf=final_time)
    # Download the Noah LSM files
    gesdisc.gesdisc_curl(lsm_urls, noahlsm_dir, debug=debug)
    '''

    """ Open one of each of the file types to extract meta-info """
    _,nldas_info,_ = grib_tools.get_grib1_data(next(nldas_dir.iterdir()))
    _,noahlsm_info,_ = grib_tools.get_grib1_data(next(noahlsm_dir.iterdir()))

    """ Load static datasets from pkl created by nldas_static_netcdf.py """
    static = pkl.load(static_pkl.open("rb"))

    """ Ask the user to pick a series of pixels to extract """
    pixels = pick_pixels(static["soil_comp"], replace_val=0)

    """
    Call a multiprocessed method to open all NLDAS-2 and/or Noah-LSM files
    and extract the data at each pixel for each time step. The returned points
    arrays are (t,p,b) shaped arrays for t times, p pixels, and b grib grids.
    """
    chunk_size = 24
    workers = 4
    times = [gesdisc.nldas2_to_time(f) for f in sorted(nldas_dir.iterdir())]
    noahlsm = np.stack(grib_tools.grib_parse_pixels(
        pixels, sorted(noahlsm_dir.iterdir()),
        chunk_size, workers, debug=debug))
    nldas = np.stack(grib_tools.grib_parse_pixels(
        pixels, sorted(nldas_dir.iterdir()),
        chunk_size, workers, debug=debug))

    t0 = times[0]
    dt = times[1]-t0

    for px in range(len(pixels)):
        for feat in range(len(noahlsm_info)):
            if noahlsm_info[feat]["name"] not in ("LSOIL", "SOILM"):
                continue
            flabel = noahlsm_info[feat]["name"] + "-" + \
                    noahlsm_info[feat]["lvl_str"].split(" ")[0]
            tmp_gts = GTS(noahlsm[:,px,feat].data, t0, dt, pixels[px], flabel)
            tmp_gts.save(gts_dir, replace=True)
        for feat in range(len(nldas_info)):
            tmp_gts = GTS(nldas[:,px,feat].data, t0, dt,
                                    pixels[px], nldas_info[feat]["name"])
            tmp_gts.save(gts_dir, replace=True)
