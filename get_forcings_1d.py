"""
This script implements the procedure for selecting and extracting a series of
single-pixel datasets from NLDAS2 and Noah-LSM files from GES DISC, both of
which are on a ~14km grid.
"""
from datetime import datetime
from pathlib import Path
import numpy as np
import pickle as pkl

from aes670hw2 import guitools as gt
from aes670hw2 import enhance as enh

import gesdisc
import grib_tools

def pick_pixels(X:np.ndarray, replace_val:list=None):
    """
    Choose a subset of pixels from a 2d array or 3d RGB, return their indeces.

    :@param X: (M,N) or (M,N,3) array or masked array to select pixels from.
        If X is 2D, the greyscale array will be rendered as an RGB using a
        default hue range of (0,.66) in HSV space.
    :@param replace_val: if X is a masked array and replace_val is a valid
        scalar value of the same type as X, replaces any masked values with
        the number prior to converting to RGB color space.
    """
    Y = enh.linear_gamma_stretch(X)
    if type(X)==np.ma.core.MaskedArray and not replace_val is None:
        Y = Y.data
        Y[np.where(X.mask)] = replace_val
    if len(Y.shape)==2:
        Y = gt.scal_to_rgb(Y, hue_range=(0,.66))
    return gt.get_category(Y, fill_color=(0,0,0), show_pool=False)

if __name__=="__main__":
    debug = True
    data_dir = Path("data/")

    #init_time = datetime(year=2018, month=8, day=1)
    #final_time = datetime(year=2018, month=10, day=1)
    init_time = datetime(year=2021, month=6, day=1)
    final_time = datetime(year=2021, month=8, day=1)

    # pkl generated by nldas_static_netcdf.py
    static_pkl = data_dir.joinpath("static/nldas2_static_all.pkl")
    # Directories containing raw hourly nldas2 and noahlsm grib1 files
    #nldas_dir = data_dir.joinpath("nldas2_20180401-20180931")
    #noahlsm_dir = data_dir.joinpath("noahlsm_20180401-20180931")
    nldas_dir = data_dir.joinpath("nldas2_20210401-20210931")
    noahlsm_dir = data_dir.joinpath("noahlsm_20210401-20210931")

    """ Load static datasets from pkl created by nldas_static_netcdf.py """
    static = pkl.load(static_pkl.open("rb"))
    print(static.keys())

    '''
    """ Download all of the files within the provided time range """
    nldas_dir = data_dir.joinpath("nldas2_20180401-20180931")
    noahlsm_dir = data_dir.joinpath("noahlsm_20180401-20180931")
    # Generate strings for each hourly nldas2 file in the time range
    nldas_urls = gesdisc.hourly_nldas2_urls(t0=init_time, tf=final_time)
    gesdisc.gesdisc_curl(nldas_urls, nldas_dir, debug=debug)
    # Generate strings for each hourly Noah-LSM file in the time range.
    lsm_urls = gesdisc.hourly_noahlsm_urls(t0=init_time, tf=final_time)
    # Download the Noah LSM files
    gesdisc.gesdisc_curl(lsm_urls, noahlsm_dir, debug=debug)
    '''

    _,nldas_info,_ = grib_tools.get_grib1_data(next(nldas_dir.iterdir()))
    _,noahlsm_info,_ = grib_tools.get_grib1_data(next(noahlsm_dir.iterdir()))

    #'''
    """ Ask the user to pick a series of pixels to extract """
    pixels = pick_pixels(static["soil_comp"], replace_val=0)
    #'''

    #'''
    """
    Call a multiprocessed method to open all NLDAS-2 and/or Noah-LSM files
    and extract the data at each pixel for each time step. The returned points
    arrays are (t,p,b) shaped arrays for t times, p pixels, and b grib grids.
    """
    chunk_size = 24
    workers = 4
    times = [gesdisc.nldas2_to_time(f) for f in nldas_dir.iterdir()]
    lsm_points = grib_tools.grib_parse_pixels(
            pixels, noahlsm_dir.iterdir(), chunk_size, workers, debug=debug)
    nldas_points = grib_tools.grib_parse_pixels(
            pixels, nldas_dir.iterdir(), chunk_size, workers, debug=debug)

    pkl.dump((lsm_points,nldas_points,pixels,times,nldas_info,noahlsm_info),
             Path("data/buffer/tmp.pkl").open("wb"))


