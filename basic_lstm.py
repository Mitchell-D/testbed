import pickle as pkl
from pathlib import Path
import numpy as np
from datetime import datetime
from datetime import timedelta

# It's temporary thanks to warnings from the conda build of tensorflow I need
import warnings
warnings.filterwarnings("ignore")

from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import InputLayer, LSTM, Dense
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.optimizers import Adam


def basic_deep_lstm(window_size:int, feature_dims:int, output_dims:int):
    """
    -> batch shape: (batch_size, window_size, feature_dims)
    -> output shape: (batch_size, output_dims)

    batch shape:
    Batch size is (timesteps - window_size) since the first "window"
    of features must be used to inform the next time step in training.

    :@param 1d_data_dict: Dictionary of 1D data following the standard of
        dictionaries generated by make_1d_dataset.py
    :@param window_size: Number of former timesteps of input features
        that are trained on for each additional prediction. To my
        understanding, periodic features with a frequency less than the time
        window won't be fully characterized unless the LSTM is stateful.
    """
    nldas1D = Sequential()

    # First layer's output shape is (batch_size, window_size, hidden_size)
    # since return_sequences is True. This returns a 3D tensor containing an
    # abstract time series sequence for the next LSTM layer to process.
    nldas1D.add(LSTM(
        units=64,
        input_shape=(window_size, feature_dims),
        # Return sequences of input
        return_sequences=True,
        activation="relu",
        ))
    # return_sequences set to False here to collapse a dimension
    nldas1D.add(LSTM(units=32, return_sequences=False))
    nldas1D.add(Dense(units=8, activation='relu'))
    nldas1D.add(Dense(units=output_dims, activation='linear'))
    nldas1D.compile(optimizer="adam", loss="mse")

    nldas1D.summary()
    return nldas1D

if __name__=="__main__":
    # First cycle only
    #training_pkl = Path("data/model_data/silty-loam_set1_training.pkl")
    #validation_pkl = Path("data/model_data/silty-loam_set1_validation.pkl")
    model_dir = Path("models/set004")

    # All cycles
    t_pkl = model_dir.joinpath("input/silty-loam_set4_training.pkl")
    v_pkl = model_dir.joinpath("input/silty-loam_set4_validation.pkl")
    s_pkl = model_dir.joinpath("input/silty-loam_set4_testing.pkl")

    #checkpoint_file = Path("data/model_check/set001")
    checkpoint_file = model_dir.joinpath("checkpoint")

    t_feat,t_truth,t_times = pkl.load(t_pkl.open("rb"))
    v_feat,v_truth,v_times = pkl.load(v_pkl.open("rb"))
    s_feat,s_truth,s_times = pkl.load(s_pkl.open("rb"))

    print(t_feat.shape,v_feat.shape,s_feat.shape)
    #'''
    # set1: 5 epochs, first cycle
    # set2: 200 epochs, first cycle
    # set3: 600 epochs, all 4 cycles
    EPOCHS = 600
    model = basic_deep_lstm(
            window_size=48,
            feature_dims=t_feat.shape[2],
            output_dims=t_truth.shape[1],
            )
    check = ModelCheckpoint(checkpoint_file.as_posix(), save_best_only=True)
    model.compile(
            loss=MeanSquaredError(),
            optimizer=Adam(learning_rate=1e-4),
            metrics=[RootMeanSquaredError()],
            )
    model.fit(
            t_feat,
            t_truth,
            validation_data=(v_feat, v_truth),
            #epochs=30,
            epochs=EPOCHS,
            callbacks=[check],
            )
    #'''

    """
    Re-load the model and generate predictions for training, validation, and
    testing data.
    """
    print(f"Loading {checkpoint_file.as_posix()}")
    model = load_model(checkpoint_file.as_posix())
    model.compile(optimizer='adam')

    t_out = model.predict(t_feat)
    v_out = model.predict(v_feat)
    s_out = model.predict(s_feat)
    print("features:",t_feat.shape,v_feat.shape,s_feat.shape)
    print("outputs:",t_out.shape, v_out.shape, s_out.shape)
    pkl.dump((t_out, v_out, s_out),
             model_dir.joinpath("output/silty-loam_set003_out.pkl").open("wb"))
