import pickle as pkl
from pathlib import Path
import numpy as np
from datetime import datetime
from datetime import timedelta

# It's temporary thanks to warnings from the conda build of tensorflow I need
import warnings
warnings.filterwarnings("ignore")

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import InputLayer, LSTM, Dense
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.optimizers import Adam

def basic_deep_lstm(time_window_size:int, feature_dims:int, output_dims:int):
    """
    -> batch shape: (batch_size, time_window_size, feature_dims)
    -> input shape: (time_window_size, feature_dims)
    -> output shape: (batch size, output dimensions)

    batch shape:
    Batch size is (timesteps - time_window_size) since the first "window"
    of features must be used to inform the next time step in training.

    :@param 1d_data_dict: Dictionary of 1D data following the standard of
        dictionaries generated by make_1d_dataset.py
    :@param time_window_size: Number of former timesteps of input features
        that are trained on for each additional prediction. To my
        understanding, periodic features with a frequency less than the time
        window won't be fully characterized unless the LSTM is stateful.
    """
    nldas1D = Sequential()

    # First layer's output shape is (batch_size, window_size, hidden_size)
    # since return_sequences is True. This returns a 3D tensor containing an
    # abstract time series sequence for the next LSTM layer to process.
    nldas1D.add(LSTM(
        units=64,
        input_shape=(time_window_size, feature_dims),
        # Return sequences of input
        return_sequences=True,
        activation="relu",
        ))
    # return_sequences set to False here to collapse a dimension
    nldas1D.add(LSTM(units=32, return_sequences=False))
    nldas1D.add(Dense(units=8, activation='relu'))
    nldas1D.add(Dense(units=output_dims, activation='linear'))
    nldas1D.compile(optimizer="adam", loss="mse")

    nldas1D.summary()
    return nldas1D

if __name__=="__main__":
    """
    1D datasets are produced by build_1d_dataset, and are formatted as such:
    {
        "feature":ndarray shaped like (timesteps, pixels, feature_bands),
        "truth":ndarray shaped like (timesteps, pixels, output_bands),
        "static":ndarray shaped like (1, pixels, static_datasets),
        "info":{
            "feature":List of dicts for each input band (size feature_bands),
            "truth":List of dicts for each out band (size output_bands),
            "static":List of dicts for static data (size static_datasets),
        }
        "geo":ndarray shaped like (nlat, nlon) for coordinates
        "pixels":List of 2-tuples corresponding to indeces of each pixel.
    }
    """
    debug = True
    data_dir = Path("data")
    fig_dir = Path("figures")
    # set_label denotes a dataset of unique selected pixels
    set_label = "silty-loam"
    #data_pkl = data_dir.joinpath(Path("1D/silty-loam_2019.pkl"))
    data_pkl = data_dir.joinpath(Path("1D/silty-loam_2019_lsoil.pkl"))
    data_dict = pkl.load(data_pkl.open("rb"))

    timesteps = data_dict["timesteps"]

    # For now, select only spring and summer months
    t0 = datetime(year=2019, month=4, day=1, hour=0)
    dt = timedelta(hours=1)
    num_cycles = 4
    batch_size = 24*28
    validation_size = 24*7
    testing_size = 24*7
    window_size = 24*2

    cycle_size = 3*window_size + batch_size + validation_size + testing_size
    tf = t0 + dt * cycle_size * num_cycles

    # Copy static datasets across timesteps and append them as new features.
    # Features are still in (timestep, pixel, feature) format, as provided
    # in the 1D dataset dictionary
    features = data_dict["feature"]
    static = np.vstack([data_dict["static"] for i in range(features.shape[0])])
    # Subset all relevant datasets to the time constraint
    sub_slice = slice(timesteps.index(t0), timesteps.index(tf))
    truth = data_dict["truth"][sub_slice]
    features = np.dstack((features, static))[sub_slice]
    timesteps = timesteps[sub_slice]

    training = []
    validation = []
    testing = []
    # Each cycle covers 1152 time steps
    print("cycle size:", cycle_size)
    print("features/truth shape:", features.shape, truth.shape)
    for i in range(features.shape[0]//cycle_size):
        window_slice = lambda start,pos,wdw: slice(start+pos,start+pos+wdw)

        # Uses sliding window to construct an array like
        # (batch_size,window,pixels,features)
        t_start = i*cycle_size
        training = np.vstack([
            np.expand_dims(features[window_slice(t_start,j,window_size)],0)
            for j in range(batch_size)])

        # Uses sliding window to construct an array like
        # (validation_size,window,pixels,features)
        v_start = t_start+batch_size+window_size
        validation = np.vstack([
            np.expand_dims(features[window_slice(v_start,j,window_size)],0)
            for j in range(validation_size)])

        # Uses sliding window to construct an array like
        # (testing_size,window,pixels,features)
        s_start = v_start+validation_size+window_size
        testing = np.vstack([
            np.expand_dims(features[window_slice(s_start,j,window_size)],0)
            for j in range(testing_size)])

        print(training.shape, validation.shape, testing.shape)
        print(training.shape[0]+validation.shape[0]+testing.shape[0])

        '''
        # (4560 samples/batch, 48 steps/sample,
        #  12 pixels, 21 features/pixel)
        print(training.shape)
        training = np.vstack(
                [training[:,:,px,:] for px in range(training.shape[2])])
        # (8064,48,21)
        print(training.shape)
        '''
        exit(0)

        tmp_t = slice(start_idx,start_idx+batch_size+window_size)
        #tmp_v = slice(tmp_t.stop, tmp_t.stop+validation_size+window_size)
        #tmp_s = slice(tmp_v.stop, tmp_v.stop+testing_size+window_size)
        #print(tmp_t, tmp_v, tmp_s)
    exit(0)

    model = basic_deep_lstm(
            time_window_size=48,
            feature_dims=features.shape[2],
            output_dims=data_dict["truth"].shape[2]
            )

    print(len(timesteps), features.shape)
