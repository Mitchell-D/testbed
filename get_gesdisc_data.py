""" Simple script downloading NoahLSM and NLDAS-2 from GES DISC """
from datetime import datetime
from datetime import timedelta
from pathlib import Path
import pickle as pkl

from krttdkit.acquire import gesdisc
from krttdkit.acquire import grib_tools
#from GeoTimeSeries import GeoTimeSeries as GTS

if __name__=="__main__":
    debug = True
    data_dir = Path("data/")

    # pkl generated by nldas_static_netcdf.py
    static_pkl = data_dir.joinpath("static/nldas2_static_all.pkl")

    # Directories containing raw hourly nldas2 and noahlsm grib1 files
    nldas_dir = data_dir.joinpath("nldas2_grib")
    noahlsm_dir = data_dir.joinpath("noahlsm_grib")

    """ Download all of the files within the provided time range """
    ## currently have: 2015, 2016, 2017, 2019, 2021
    init_time = datetime(year=2015, month=1, day=1)
    final_time = datetime(year=2022, month=1, day=1)

    # Generate strings for each hourly NLDAS2 file in the time range
    nldas_urls = gesdisc.hourly_nldas2_urls(t0=init_time, tf=final_time)
    # Generate strings for each hourly Noah-LSM file in the time range.
    lsm_urls = gesdisc.hourly_noahlsm_urls(t0=init_time, tf=final_time)

    '''
    # Download the NLDAS2 files
    gesdisc.gesdisc_curl(nldas_urls, nldas_dir, debug=debug)
    # Download the Noah LSM files
    gesdisc.gesdisc_curl(lsm_urls, noahlsm_dir, debug=debug)
    '''

    """ Open one of each of the file types to extract meta-info """
    nldas,nldas_info,nldas_geo = grib_tools.get_grib1_data(
            next(nldas_dir.iterdir()),
            wgrib_bin="/rhome/mdodson/.micromamba/bin/wgrib",
            )
    noahlsm,noahlsm_info,noahlsm_geo = grib_tools.get_grib1_data(
            next(noahlsm_dir.iterdir()),
            wgrib_bin="/rhome/mdodson/.micromamba/bin/wgrib",
            )

    """ Load static datasets from pkl created by nldas_static_netcdf.py """
    static = pkl.load(static_pkl.open("rb"))

    print(nldas_info)
    print(noahlsm_info)
    print(static.keys())
